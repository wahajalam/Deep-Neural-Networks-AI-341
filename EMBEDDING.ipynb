{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ5aYHHT896W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ0bv5TB0YAq"
      },
      "outputs": [],
      "source": [
        "new_sentences = [\n",
        "    \"I received a promotion at work today, and I'm absolutely thrilled!\",\n",
        "    \"The weather is beautiful, and I'm looking forward to a day at the beach.\",\n",
        "    \"I failed my driving test, and I'm feeling really down.\",\n",
        "    \"The restaurant service was terrible, and the food was cold.\",\n",
        "    \"Today's weather is neither too hot nor too cold; it's just right.\",\n",
        "    \"i hate it\",\n",
        "    \"i adore it \",\n",
        "    \"i hate that\",\n",
        "    \"i like that\"\n",
        "\n",
        "\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [1, 1, 0, 0, 1, 0, 1, 0, 1]\n"
      ],
      "metadata": {
        "id": "BW4C8qkr9G8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and removing punctuation\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(new_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Remove punctuation and convert to lowercase\n",
        "sentences = []\n",
        "for sentence in new_sentences:\n",
        "    sentence = sentence.lower()\n",
        "    sentence = ''.join([c for c in sentence if c.isalnum() or c.isspace()])\n",
        "    sentences.append(sentence)\n",
        "\n",
        "# Tokenize the sentences\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "max_sequence_length = max([len(sequence) for sequence in sequences])\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n"
      ],
      "metadata": {
        "id": "-oryI0dG9I2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    Embedding(len(word_index) + 1, 64, input_length=max_sequence_length),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Train the model\n",
        "model.fit(data, labels, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry1w_kY39Kiy",
        "outputId": "038e4805-7a08-475e-c23b-cbd94317fd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6932 - accuracy: 0.5556\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6902 - accuracy: 0.5556\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6875 - accuracy: 0.5556\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6851 - accuracy: 0.6667\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6820 - accuracy: 0.6667\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6790 - accuracy: 0.5556\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6755 - accuracy: 0.5556\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6716 - accuracy: 0.5556\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6669 - accuracy: 0.5556\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6612 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6f3da47a60>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional test sentences\n",
        "test_sentences = [\n",
        "    \"I loved the movie. It was fantastic!\",\n",
        "    \"The restaurant was terrible, and the service was awful.\",\n",
        "    \"This book is so-so. Not great, not terrible.\",\n",
        "    \"The weather today is wonderful.\",\n",
        "\n",
        "]\n",
        "\n",
        "# Preprocess the test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_data = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Predict sentiments for the test data\n",
        "test_predicted_probabilities = model.predict(test_data)\n",
        "test_predicted_labels = [1 if prob > 0.5 else 0 for prob in test_predicted_probabilities]\n",
        "\n",
        "# Print test sentences and their predicted sentiments\n",
        "for i in range(len(test_sentences)):\n",
        "    print(f\"Sentence: '{test_sentences[i]}' - Predicted Sentiment: {'Positive' if test_predicted_labels[i] == 1 else 'Negative'}\")\n",
        "\n",
        "# Evaluate the accuracy of the model on the test data using scikit-learn\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_labels = [1, 0, 1]\n",
        "test_accuracy = accuracy_score(test_labels, test_predicted_labels)\n",
        "print(\"Test Data Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "JZzjGqVB9MsC",
        "outputId": "b90d9ed7-8954-4b93-d061-22d8fde9be1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4bd2f4fd7879>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Preprocess the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_probabilities = model.predict(data)\n",
        "\n",
        "# Apply a threshold (e.g., 0.5) to determine sentiment labels\n",
        "predicted_labels = [1 if prob > 0.5 else 0 for prob in predicted_probabilities]\n",
        "\n",
        "print(\"Predicted Sentiments:\", predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8v630YX9Qzi",
        "outputId": "84e2da1a-ae68-4a41-cbfd-6198dd7217c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted Sentiments: [1, 1, 1, 1, 1, 0, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7OjUZbC9tDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}